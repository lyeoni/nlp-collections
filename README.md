# NLP-Collections
Collection of Natural Language Processing Models and References 

## Attention & Transformer
- ****`PAPER`**** [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
- ****`POST`**** [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- ****`POST`**** [Transformer Architecture: Attention Is All You Need](https://medium.com/@adityathiruvengadam/transformer-architecture-attention-is-all-you-need-aeccd9f50d09)

## Language Modeling
- ****`PAPER`**** [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- ****`VIDEO(Korean ver.)`**** [PR-121: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://www.youtube.com/watch?v=GK4IO3qOnLc)
- ****`VIDEO(Korean ver.)`**** [#BERT #충격적인논문 #ClovaAI](https://www.facebook.com/hunkims/videos/10156797151174521/)
- ****`VIDEO(Korean ver.)`**** [BERT 세미나 - TmaxData NLP 박민호](https://www.youtube.com/watch?v=2b7_iq8rAVY&t=367s)
